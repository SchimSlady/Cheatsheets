{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Cheatsheet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# File reading/writing\n",
    "df = pd.read_csv(\"data.csv\")  # pd.read_csv(\"data.csv\", delimiter=\";\") for structure\n",
    "df.to_csv(\"output.csv\")\n",
    "\n",
    "# Access columns and rows\n",
    "df['column']\n",
    "df.iloc[0]\n",
    "df.loc[0, 'column']\n",
    "\n",
    "# Get help\n",
    "help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index # Index of the DataFrame\n",
    "df.head() # Display first 5 rows\n",
    "df.tail() # Display last 5 rows\n",
    "df.shape # Returns (rows, columns)\n",
    "df.columns # List column names\n",
    "df.info() # Summary of the DataFrame\n",
    "print(df.isna().any()) #print columns that have NAs\n",
    "df.describe() # Statistical summary of numeric columns\n",
    "df.dtypes # Data type of each column\n",
    "df.isnull() # Missing values in each column\n",
    "df.isna() # NaN values in each column\n",
    "df[\"col\"].any() # Check if any value in boolean column is True\n",
    "df[\"col\"].all() # Check if all values in boolean column are True\n",
    "df.corr() # Correlation matrix\n",
    "df['col'].unique() # Unique values in a column\n",
    "df['col'].sum() # Sum of a column\n",
    "df['col'].min() # Minimum of a column\n",
    "df['col'].max() # Maximum of a column\n",
    "df['col'].argmax() # Returns int Position of Max value row\n",
    "df['col'].mean() # Mean of a column\n",
    "df['col'].std() # Standard deviation of a column\n",
    "df['col'].var() # Variance of a column\n",
    "df['col'].idxmax() # Get maximizing index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['column'] # Select column as Series\n",
    "df[['col1', 'col2']] # Select multiple columns as DataFrame\n",
    "df.iloc[0, 1] # Select by row and column index\n",
    "df.loc[0, 'col'] # Select by label\n",
    "x = data.loc[data['Column1'] == Value, 'Column2'] # Beispiel um Wert in Spalte 2 an der Stelle von Value in Spalte 1 rauszufinden\n",
    "df.iloc[0:3] # Select rows by index\n",
    "df[df['col'] > 10] # Filter rows by condition (also with .loc)\n",
    "\n",
    "\n",
    "# Filters\n",
    "\n",
    "f = df['col'] > 10 # Returns a Series element with boolean values\n",
    "df[f] # Selects rows by filter\n",
    "\n",
    "# Combined filters\n",
    "f = (df['col1'] > 10) & (df['col2'] == 'a') # logical 'and'\n",
    "f = (df['col1'] > 10) | (df['col2'] == 'a') # logical 'or'\n",
    "\n",
    "# Useful filter functions\n",
    "f = df['col'].between(10, 20)\n",
    "f = df['col'].isin(list_of_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation\n",
    "To modify the DataFrame in place, use the argument inplace=True. Alternatively, you\n",
    "can assign the result to a new DataFrame or overwrite existing columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_col'] = df['col1'] + df['col2'] # Add new column\n",
    "df.rename(columns={'old_name': 'new_name'}) # Rename column\n",
    "df.replace({1: 2, \"a\": \"b\"}) # Replace values\n",
    "df.drop('col', axis=1) # Drop column\n",
    "df.drop(1, axis=0) # Drop row\n",
    "df.dropna() # Drop missing values e.g., data = data.dropna(subset=[\"delivery_date\"])\n",
    "df.fillna(0) # Fill missing values\n",
    "df.sort_values(by='col') # Sort DataFrame by column\n",
    "df.apply(foo, axis=1) # Apply function across columns/rows\n",
    "df['col'].apply(foo) # Apply function across values of a Series\n",
    "df['col'].map(foo) # Apply function across values of a Series\n",
    "df['col'].where(df['col'] > 0, 0) # Replace all values where cond. is False\n",
    "df['col'].astype(int) # Convert column to integers\n",
    "df['col'].astype('category') # Convert column to categorical numbers\n",
    "df['col'].cat.codes # Convert categorical to numerical values\n",
    "pd.cut(df['col'], 3) # Sort values into bins\n",
    "pd.Series(pd.Categorical(data[\"size\"], categories=[\"S\", \"M\", \"L\", \"XL\", \"XXL\", \"XXXL\"], ordered=True)) #ordinal values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('col') # Group by column 'col'\n",
    "df.groupby('col')['Attribute'].mean() # Group by column 'col' and calculate the related Attribute Average for example\n",
    "df.agg({'col': 'sum'}) # Aggregate using functions\n",
    "df.value_counts(normalize=False) # Frequency count of values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging and Joining\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on='key', how='outer') # Merge dfs on a key column (Outer join == All key value Zeilen, Inner Join == nur Ã¼bereinstimmende Key Value Zeilen)\n",
    "df1.join(df2) # Join DataFrames on index\n",
    "pd.concat([df1, df2]) # Concatenate DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert values to Datetime\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\", format=\"%Y-%m-%d\")\n",
    "# Receive information from Datetime\n",
    "df[\"date\"].dt.dayofweek\n",
    "df[\"date\"].dt.day\n",
    "df[\"date\"].dt.month\n",
    "df[\"date\"].dt.year\n",
    "df[\"date\"].dt.quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='col1', y='col2') # Line plot\n",
    "df[\"col1\"].plot.hist(bins=20)# Histogram\n",
    "df.plot(x='col1', y=['col2', 'col3'], kind='bar') # Bar plot\n",
    "df.plot(x='col1', y='col2', kind='scatter') # Scatter plot\n",
    "df.plot.box(column=\"Col1\", by=\"Col2\") #box plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matplotlib Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Line plot\n",
    "plt.plot(df['col1'], df['col2'])\n",
    "\n",
    "# Title, annotations, and prettifications\n",
    "plt.title(\"Title\")\n",
    "plt.xlabel(\"X-axis label\")\n",
    "plt.ylabel(\"Y-axis label\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "# Save plot\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selected models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.LinearRegression()\n",
    "linear_model.Ridge()\n",
    "ensemble.AdaBoostRegressor(\n",
    "# Base model can be changed ...\n",
    "estimator=tree.DecisionTreeRegressor(max_depth=2),\n",
    "n_estimators=10\n",
    ")\n",
    "ensemble.RandomForestRegressor(n_estimators=100, max_depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.LogisticRegression()\n",
    "tree.DecisionTreeClassifier(max_depth=10)\n",
    "ensemble.AdaBoostClassifier(\n",
    "# Base model can be changed ...\n",
    "estimator=DecisionTreeClassifier(max_depth=10),\n",
    "n_estimators=10\n",
    ")\n",
    "ensemble.RandomForestClassifier(n_estimators=10, max_depth=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.KMeans(n_clusters=8, max_iter=100) # K-Means\n",
    "cluster.AgglomerativeClustering( # Hierarchical clustering\n",
    "n_clusters=10, metric=\"euclidean\", linkage=\"single\"\n",
    ")\n",
    "mixture.GaussianMixture(n_components=4) # EM-Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training und Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For supervised methods:\n",
    "model.fit(x, y)\n",
    "model.predict(x)\n",
    "model.fit_predict(x, y)\n",
    "# For unsupervised methods:\n",
    "model.fit(x)\n",
    "model.predict(x) # May not be available for all models\n",
    "model.fit_predict(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics, Scaling, Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "# Regression\n",
    "metrics.mean_absolute_error(y_true, y_pred) # Mean absolute error\n",
    "metrics.mean_squared_error(y_true, y_pred) # Mean squared error\n",
    "metrics.root_mean_squared_error(y_true, y_pred) # Root mean squared error\n",
    "metrics.explained_variance_score(y_true, y_pred) # Explained variance\n",
    "\n",
    "# Classification\n",
    "metrics.accuracy_score(y_true, y_pred) # Accuracy\n",
    "metrics.balanced_accuracy_score(y_true, y_pred) # Balanced Accuracy !!!!!\n",
    "metrics.f1_score(y_true, y_pred) # F1 score\n",
    "\n",
    "# Scaling\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x)\n",
    "scaler.transform(x)\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# With numpy arrays for X and y\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# With one pandas dataframe\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
